{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Antimicrobial Peptide Classification - Student Assignment\n",
    "\n",
    "---\n",
    "\n",
    "## üß¨ Problem Statement: Why Antimicrobial Peptide Classification?\n",
    "\n",
    "### What are Antimicrobial Peptides (AMPs)?\n",
    "\n",
    "Antimicrobial peptides (AMPs) are small proteins that play a crucial role in the innate immune system of all living organisms. They are:\n",
    "\n",
    "- **Natural antibiotics**: Part of the body's first line of defense against pathogens\n",
    "- **Broad-spectrum**: Effective against bacteria, fungi, viruses, and even cancer cells\n",
    "- **Fast-acting**: Kill microbes within minutes\n",
    "- **Low resistance**: Pathogens develop resistance much slower compared to conventional antibiotics\n",
    "\n",
    "### Why is This Problem Important?\n",
    "\n",
    "#### 1. **Antibiotic Resistance Crisis** üö®\n",
    "- Traditional antibiotics are becoming ineffective due to bacterial resistance\n",
    "- WHO lists antibiotic resistance as one of the top 10 global public health threats\n",
    "- By 2050, antimicrobial resistance could cause 10 million deaths annually\n",
    "- **AMPs offer a promising alternative** with lower resistance development\n",
    "\n",
    "#### 2. **Drug Discovery** üíä\n",
    "- Identifying AMPs from protein sequences can accelerate drug development\n",
    "- Computational prediction is **faster and cheaper** than experimental screening\n",
    "- Can screen millions of sequences in silico before lab testing\n",
    "- Reduces time from discovery to clinical trials\n",
    "\n",
    "#### 3. **Personalized Medicine** üè•\n",
    "- Understanding human AMPs helps in:\n",
    "  - Diagnosing immune deficiencies\n",
    "  - Developing targeted therapies\n",
    "  - Understanding disease susceptibility\n",
    "  - Creating personalized treatment plans\n",
    "\n",
    "#### 4. **Agricultural Applications** üåæ\n",
    "- AMPs can protect crops from pathogens\n",
    "- Reduce need for chemical pesticides\n",
    "- Improve food security\n",
    "\n",
    "### The Computational Challenge\n",
    "\n",
    "**Problem**: Given a protein sequence, can we predict whether it has antimicrobial properties?\n",
    "\n",
    "**Why Machine Learning?**\n",
    "- Experimental validation is expensive (\\$10,000+ per peptide)\n",
    "- Time-consuming (months to years)\n",
    "- ML can screen thousands of candidates in hours\n",
    "- Accuracy of 80-95% can significantly reduce experimental workload\n",
    "\n",
    "**Real-World Impact**:\n",
    "- Pharmaceutical companies use these models to identify drug candidates\n",
    "- Researchers discover new AMPs from genomic databases\n",
    "- Helps combat emerging infectious diseases\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Dataset Overview\n",
    "\n",
    "### Dataset Description\n",
    "\n",
    "**File**: `antimicrobial_peptide.csv`\n",
    "\n",
    "**Size**: 2,000 protein sequences from human proteins (Homo sapiens)\n",
    "\n",
    "**Source**: UniProt database (Universal Protein Resource)\n",
    "- UniProt is the world's most comprehensive catalog of protein sequences\n",
    "- Contains experimentally validated and computationally predicted proteins\n",
    "- Our data comes from human proteome (taxonomy ID: 9606)\n",
    "\n",
    "### Class Labels\n",
    "\n",
    "The dataset contains two classes:\n",
    "\n",
    "| Label | Class | Count | Description |\n",
    "|-------|-------|-------|-------------|\n",
    "| **0** | Non-AMP | 1,000 | Regular proteins without antimicrobial activity |\n",
    "| **1** | AMP | 1,000 | Proteins with antimicrobial properties |\n",
    "\n",
    "**Balanced Dataset**: Equal number of samples per class (1,000 each)\n",
    "- Prevents bias toward majority class\n",
    "- Ensures fair model training\n",
    "- Simplifies evaluation metrics\n",
    "\n",
    "### Sequence Characteristics\n",
    "\n",
    "**Overall Statistics**:\n",
    "- **Mean length**: ~419 amino acids\n",
    "- **Median length**: ~317 amino acids\n",
    "- **Range**: 32 to 7,592 amino acids\n",
    "\n",
    "**By Class**:\n",
    "- **Label 0 (Non-AMP)**: Mean = 333 aa, Median = 271 aa\n",
    "- **Label 1 (AMP)**: Mean = 505 aa, Median = 387 aa\n",
    "\n",
    "### Biological Context\n",
    "\n",
    "#### What Makes a Protein Antimicrobial?\n",
    "\n",
    "AMPs typically have these characteristics:\n",
    "\n",
    "1. **Positive Charge**\n",
    "   - Rich in lysine (K) and arginine (R)\n",
    "   - Attracts to negatively charged bacterial membranes\n",
    "\n",
    "2. **Amphipathic Structure**\n",
    "   - Contains both hydrophobic and hydrophilic regions\n",
    "   - Allows insertion into lipid membranes\n",
    "\n",
    "3. **Small to Medium Size**\n",
    "   - Typically 10-50 amino acids (though our dataset includes larger proteins)\n",
    "   - Easier to penetrate cell membranes\n",
    "\n",
    "4. **Specific Amino Acid Composition**\n",
    "   - High content of: K, R, W, F, L\n",
    "   - Low content of: E, D (negatively charged)\n",
    "\n",
    "#### Mechanism of Action\n",
    "\n",
    "AMPs kill microbes by:\n",
    "1. **Membrane Disruption**: Creating pores in bacterial membranes\n",
    "2. **Intracellular Targets**: Inhibiting DNA/RNA synthesis\n",
    "3. **Immune Modulation**: Activating immune responses\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Your Task\n",
    "\n",
    "You will implement a complete machine learning pipeline to classify antimicrobial peptides:\n",
    "\n",
    "### Part 1: Data Exploration\n",
    "- Load and examine the dataset\n",
    "- Visualize class distribution\n",
    "- Analyze sequence length patterns\n",
    "- Compare amino acid composition between classes\n",
    "\n",
    "### Part 2: Feature Extraction\n",
    "Implement three different feature extraction methods:\n",
    "\n",
    "#### 2.1 AAC (Amino Acid Composition)\n",
    "- **What**: Frequency of each of the 20 standard amino acids\n",
    "- **Dimension**: 20 features\n",
    "- **Pros**: Simple, interpretable, captures basic composition\n",
    "- **Cons**: Loses sequence order information\n",
    "\n",
    "#### 2.2 k-mers (Tri-peptides)\n",
    "- **What**: Frequency of overlapping 3-amino-acid subsequences\n",
    "- **Dimension**: 500 features (top 500 most common tri-peptides)\n",
    "- **Pros**: Captures local sequence patterns, preserves some order\n",
    "- **Cons**: Still limited context window\n",
    "\n",
    "#### 2.3 ProtVec (Word2Vec Embeddings)\n",
    "- **What**: Learned vector representations using Word2Vec on k-mers\n",
    "- **Dimension**: 100 features\n",
    "- **Pros**: Captures semantic relationships, dense representation\n",
    "- **Cons**: Less interpretable, requires training\n",
    "\n",
    "### Part 3: Model Training\n",
    "Train three classifiers on each feature set:\n",
    "1. **Logistic Regression**: Linear baseline\n",
    "2. **Random Forest**: Non-linear ensemble method\n",
    "3. **SVM**: Kernel-based classifier\n",
    "\n",
    "**Total**: 3 features √ó 3 classifiers = 9 models\n",
    "\n",
    "### Part 4: Evaluation\n",
    "Evaluate models using:\n",
    "- **Accuracy**: Overall correctness\n",
    "- **Precision**: How many predicted AMPs are actually AMPs?\n",
    "- **Recall**: How many actual AMPs did we find?\n",
    "- **F1-Score**: Harmonic mean of precision and recall\n",
    "- **AUC-ROC**: Area under ROC curve\n",
    "- **Cross-Validation**: 5-fold CV for robust estimation\n",
    "\n",
    "### Part 5: Visualization & Interpretation\n",
    "- Compare performance across features and classifiers\n",
    "- Generate ROC curves\n",
    "- Create confusion matrices\n",
    "- Visualize embeddings (PCA)\n",
    "- Identify best model\n",
    "\n",
    "---\n",
    "\n",
    "## üìñ Background: Feature Extraction Methods\n",
    "\n",
    "### Why Different Features?\n",
    "\n",
    "Different features capture different aspects of protein sequences:\n",
    "\n",
    "| Feature | What it Captures | Best For |\n",
    "|---------|------------------|----------|\n",
    "| **AAC** | Overall composition | Quick baseline, interpretable |\n",
    "| **k-mer** | Local patterns, motifs | Functional sites, domains |\n",
    "| **ProtVec** | Semantic relationships | Complex patterns, context |\n",
    "\n",
    "### Evolution of Protein Feature Extraction\n",
    "\n",
    "1. **1990s**: Hand-crafted features (AAC, physicochemical properties)\n",
    "2. **2000s**: Sequence-based features (k-mers, position-specific)\n",
    "3. **2010s**: Embedding methods (ProtVec, inspired by NLP)\n",
    "4. **2020s**: Deep learning (ESM, ProtBERT - transformers)\n",
    "\n",
    "This assignment covers methods from eras 1-3, giving you a comprehensive understanding!\n",
    "\n",
    "---\n",
    "\n",
    "## üî¨ Expected Results\n",
    "\n",
    "Based on similar studies, you should expect:\n",
    "\n",
    "| Feature | Expected F1-Score | Why? |\n",
    "|---------|-------------------|------|\n",
    "| AAC | 0.65 - 0.75 | Simple features, limited information |\n",
    "| k-mer | 0.75 - 0.85 | Captures local patterns |\n",
    "| ProtVec | 0.80 - 0.88 | Learned representations, semantic meaning |\n",
    "\n",
    "**Best Classifier**: Usually Random Forest or SVM (non-linear methods)\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Tips for Success\n",
    "\n",
    "1. **Start Simple**: Implement AAC first, then move to more complex features\n",
    "2. **Test Incrementally**: Test each function with a small example before running on full dataset\n",
    "3. **Use Random Seeds**: Set `random_state=42` everywhere for reproducibility\n",
    "4. **Standardize Features**: Always scale features before training (use `StandardScaler`)\n",
    "5. **Cross-Validate**: Don't rely only on test set performance\n",
    "6. **Visualize**: Plots help you understand what's happening\n",
    "7. **Compare**: The goal is to compare different approaches, not just get high accuracy\n",
    "\n",
    "**Data Splitting**:\n",
    "- Training: 80% (1,600 sequences)\n",
    "- Testing: 20% (400 sequences)\n",
    "- Use stratified split to maintain class balance\n",
    "\n",
    "**Random Seed**: 42 (for reproducibility)\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Let's Begin!\n",
    "\n",
    "Now that you understand the problem and dataset, let's start implementing!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Implementation Section\n",
    "\n",
    "## TODO: Students will complete the following sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Required Packages\n",
    "\n",
    "**TODO**: Install the necessary Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Install required packages\n",
    "# Hint: !pip install -q package_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries\n",
    "\n",
    "**TODO**: Import all necessary libraries for data processing, ML, and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import libraries\n",
    "# You will need: pandas, numpy, matplotlib, seaborn, sklearn modules, gensim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Dataset\n",
    "\n",
    "**TODO**: Upload and load the antimicrobial_peptide.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Upload the dataset file\n",
    "# Hint: Use files.upload() in Colab\n",
    "\n",
    "# TODO: Load the CSV file into a pandas DataFrame\n",
    "\n",
    "# TODO: Display basic information about the dataset\n",
    "# - Number of rows and columns\n",
    "# - Column names\n",
    "# - First few rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis\n",
    "\n",
    "**TODO**: Analyze and visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check class distribution\n",
    "# How many sequences in each class (label 0 vs label 1)?\n",
    "\n",
    "# TODO: Add a column for sequence length\n",
    "\n",
    "# TODO: Calculate statistics for sequence lengths\n",
    "# - Overall mean, median, min, max\n",
    "# - By class (label 0 and label 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create visualizations\n",
    "# 1. Bar plot of class distribution\n",
    "# 2. Histogram of sequence lengths (separate by class)\n",
    "\n",
    "# Hint: Use matplotlib or seaborn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Extraction\n",
    "\n",
    "### 5.1 Amino Acid Composition (AAC)\n",
    "\n",
    "**TODO**: Implement AAC feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define a function to calculate amino acid composition\n",
    "# Input: protein sequence (string)\n",
    "# Output: numpy array of 20 values (frequency of each amino acid)\n",
    "\n",
    "def amino_acid_composition(sequence):\n",
    "    \"\"\"\n",
    "    Calculate the frequency of each of the 20 standard amino acids.\n",
    "    \n",
    "    Args:\n",
    "        sequence (str): Protein sequence\n",
    "    \n",
    "    Returns:\n",
    "        np.array: 20-dimensional feature vector\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    # Hint: The 20 standard amino acids are: ACDEFGHIKLMNPQRSTVWY\n",
    "    # Calculate: count(amino_acid) / total_length for each amino acid\n",
    "    pass\n",
    "\n",
    "# TODO: Test your function with a simple example\n",
    "# Example: amino_acid_composition('ACDEFGHIKLMNPQRSTVWY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extract AAC features for all sequences in the dataset\n",
    "# Create a numpy array of shape (2000, 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 k-mer Features (Tri-peptides)\n",
    "\n",
    "**TODO**: Implement k-mer feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define a function to extract k-mers from a sequence\n",
    "def extract_kmers(sequence, k=3):\n",
    "    \"\"\"\n",
    "    Extract overlapping k-mers from a sequence.\n",
    "    \n",
    "    Args:\n",
    "        sequence (str): Protein sequence\n",
    "        k (int): Length of k-mer (default: 3)\n",
    "    \n",
    "    Returns:\n",
    "        list: List of k-mers\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    # Hint: For sequence 'ABCDE' with k=3, k-mers are: ['ABC', 'BCD', 'CDE']\n",
    "    pass\n",
    "\n",
    "# TODO: Test your function\n",
    "# Example: extract_kmers('ACDEFG', k=3) should return ['ACD', 'CDE', 'DEF', 'EFG']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find the top 500 most common k-mers across all sequences\n",
    "# Hint: Use Counter from collections module\n",
    "\n",
    "# TODO: Create k-mer frequency features for each sequence\n",
    "# For each sequence, calculate the frequency of each of the top 500 k-mers\n",
    "# Result should be a numpy array of shape (2000, 500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 ProtVec (Word2Vec Embeddings)\n",
    "\n",
    "**TODO**: Implement ProtVec feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train a Word2Vec model on k-mers\n",
    "# Steps:\n",
    "# 1. Convert each sequence to a list of k-mers (use extract_kmers function)\n",
    "# 2. Train Word2Vec model using gensim\n",
    "# 3. Parameters: vector_size=100, window=5, min_count=2, seed=42\n",
    "\n",
    "# Hint: from gensim.models import Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert sequences to ProtVec embeddings\n",
    "# For each sequence:\n",
    "# 1. Extract k-mers\n",
    "# 2. Get Word2Vec vector for each k-mer\n",
    "# 3. Average all k-mer vectors to get sequence embedding\n",
    "# Result should be a numpy array of shape (2000, 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training and Evaluation\n",
    "\n",
    "**TODO**: Train classifiers and evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split data into training and testing sets\n",
    "# Use train_test_split with:\n",
    "# - test_size=0.2\n",
    "# - random_state=42\n",
    "# - stratify=y (to maintain class balance)\n",
    "\n",
    "# Do this for each feature set (AAC, k-mer, ProtVec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define classifiers\n",
    "# 1. Logistic Regression (max_iter=1000, random_state=42)\n",
    "# 2. Random Forest (n_estimators=100, random_state=42)\n",
    "# 3. SVM (kernel='rbf', probability=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: For each feature set and each classifier:\n",
    "# 1. Standardize features using StandardScaler\n",
    "# 2. Perform 5-fold cross-validation on training set\n",
    "# 3. Train on full training set\n",
    "# 4. Predict on test set\n",
    "# 5. Calculate metrics: Accuracy, Precision, Recall, F1-Score, AUC-ROC\n",
    "# 6. Store results in a DataFrame\n",
    "\n",
    "# Total: 9 models (3 features √ó 3 classifiers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results and Visualization\n",
    "\n",
    "**TODO**: Visualize and compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a results table showing all metrics for all models\n",
    "# Display as a pandas DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analysis and Conclusions\n",
    "\n",
    "**TODO**: Answer the following questions based on your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions to Answer:\n",
    "\n",
    "1. **Which feature extraction method performed best? Why do you think that is?**\n",
    "   - YOUR ANSWER HERE\n",
    "\n",
    "2. **Which classifier worked best overall? Was it consistent across all feature types?**\n",
    "   - YOUR ANSWER HERE\n",
    "\n",
    "3. **Look at the confusion matrices. Are there more false positives or false negatives? What does this mean in the context of drug discovery?**\n",
    "   - YOUR ANSWER HERE\n",
    "\n",
    "4. **If you had access to more computational resources, what would you try next? (Hint: Think about deep learning methods like ESM or ProtBERT)**\n",
    "   - YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
